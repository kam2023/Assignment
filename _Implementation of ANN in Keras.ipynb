{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef27e16-20a2-42f3-a3ba-762e69ffc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions.\n",
    "### Install TensorFlow:\n",
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1aa58a-d553-4b99-acc4-f04fb0c5c58c",
   "metadata": {},
   "source": [
    "## Install Keras:\n",
    "\n",
    "Keras is now integrated into TensorFlow as 'tf.keras', so you don't need to install it separately. It comes bundled with TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f457c9a-3e67-4084-a3c5-413ba775064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Versions:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44623b64-01c9-46af-801d-dc50a05f06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2. Load the Wine Quality dataset and explore its dimensions.\n",
    "\n",
    "### https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\n",
    "\n",
    "import os\n",
    "import kaggle\n",
    "\n",
    "# Set your Kaggle API credentials\n",
    "os.environ['KAGGLE_USERNAME'] = 'your_kaggle_username'\n",
    "os.environ['KAGGLE_KEY'] = 'your_kaggle_api_key'\n",
    "\n",
    "# Download the Wine Quality dataset from Kaggle\n",
    "dataset_name = 'nareshbhat/wine-quality-binary-classification'\n",
    "kaggle.api.dataset_download_files(dataset_name, path='.', unzip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae95b9-25c4-47a4-9e6b-3fa8175c6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore its dimensions using Python:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_quality_data = pd.read_csv('winequalityN-binary.csv')\n",
    "\n",
    "# Explore dimensions\n",
    "rows, columns = wine_quality_data.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745fc2a-777b-4d6f-9ff7-6b521ae41be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3. Check for null values, identify categorical variables, and encode them.\n",
    "\n",
    "## Check for Null Values:\n",
    "\n",
    "# Check for null values\n",
    "null_values = wine_quality_data.isnull().sum()\n",
    "print(\"Null Values in the dataset:\")\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94999b-40fa-4f2a-9b1c-31f5e7e473df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Categorical Variables:\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_variables = wine_quality_data.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical Variables:\")\n",
    "print(categorical_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896d854-6857-4f44-b978-9230615361e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode Categorical Variables:\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "wine_quality_data_encoded = pd.get_dummies(wine_quality_data, columns=categorical_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68369576-b02c-40a9-a987-dc04870724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'wine_quality_data_encoded'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_quality_data = pd.read_csv('winequalityN-binary.csv')\n",
    "\n",
    "# Check for null values\n",
    "null_values = wine_quality_data.isnull().sum()\n",
    "print(\"Null Values in the dataset:\")\n",
    "print(null_values)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_variables = wine_quality_data.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical Variables:\")\n",
    "print(categorical_variables)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "wine_quality_data_encoded = pd.get_dummies(wine_quality_data, columns=categorical_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f6d2f-b3bb-4007-833e-667a9b3b47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, ensure you have downloaded the dataset and placed it in your working directory or specify the correct file path in the code.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine Quality dataset (replace 'winequalityN-binary.csv' with the actual file name)\n",
    "wine_quality_data = pd.read_csv('winequalityN-binary.csv')\n",
    "\n",
    "# Check for null values\n",
    "null_values = wine_quality_data.isnull().sum()\n",
    "print(\"Null Values in the dataset:\")\n",
    "print(null_values)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_variables = wine_quality_data.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical Variables:\")\n",
    "print(categorical_variables)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "wine_quality_data_encoded = pd.get_dummies(wine_quality_data, columns=categorical_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f4680-f0c5-4320-9d7b-8c6b3f333ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4. Separate the features and target variables from the dataset.\n",
    "# Assuming you've loaded and encoded the dataset as 'wine_quality_data_encoded'\n",
    "# Replace 'wine_quality_data_encoded' with your actual dataset if it's different\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = wine_quality_data_encoded.drop(columns=['quality'])  # Exclude the 'quality' column as it is the target\n",
    "y = wine_quality_data_encoded['quality']  # Target variable 'quality'\n",
    "\n",
    "# Optionally, you can convert 'y' to a numpy array if needed:\n",
    "# y = y.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370c8cc-d04f-4040-bc05-6576efcf1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5. Perform a train-test split, dividing the data into training, validation, and test datasets.\n",
    "\n",
    "# Assuming you've loaded and encoded the dataset as 'wine_quality_data_encoded'\n",
    "# Replace 'wine_quality_data_encoded' with your actual dataset if it's different\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = wine_quality_data_encoded.drop(columns=['quality'])  # Exclude the 'quality' column as it is the target\n",
    "y = wine_quality_data_encoded['quality']  # Target variable 'quality'\n",
    "\n",
    "# Optionally, you can convert 'y' to a numpy array if needed:\n",
    "# y = y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb35cc-51b7-4343-81ed-c1737ce6033f",
   "metadata": {},
   "outputs": [],
   "source": [
    " 'train_test_split' function from the 'scikit-learn' library\n",
    "    \n",
    " from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Optionally, you can print the shapes of the resulting datasets\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", X_valid.shape, y_valid.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809f8eb-6dd5-44eb-ade6-1565b9c71570",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q6. Scale the dataset using an appropriate scaling technique.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optionally, you can convert y datasets to numpy arrays if needed:\n",
    "# y_train = y_train.values\n",
    "# y_valid = y_valid.values\n",
    "# y_test = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a01c2-135a-4c63-aca3-e6601b9b852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q7. Design and implement at least two hidden layers and an output layer for the binary categorical variables.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add the input layer (input_shape should match the number of features)\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add two hidden layers with ReLU activation\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with a sigmoid activation for binary classification\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b301da-c84d-4c51-9822-56e920f58fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q8. Create a Sequential model in Keras and add the previously designed layers to it.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add the input layer (input_shape should match the number of features)\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add two hidden layers with ReLU activation\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with a sigmoid activation for binary classification\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54317be0-a7f9-49ae-b34e-92175cf7eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q9. Print the summary of the model architecture.\n",
    "\n",
    "# Print the summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9bf06-4301-44c4-a4f1-42d551a2ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This summary provides a detailed overview of the layers in your model, the output shapes, and the number of trainable parameters in each layer.\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #\n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, num_features)]     0\n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 64)                4160\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 32)                2080\n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 33\n",
    "=================================================================\n",
    "Total params: 6,273\n",
    "Trainable params: 6,273\n",
    "Non-trainable params: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5c9ba-debb-4edf-94ba-4c46354f493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q10. Set the loss function(‘binary_crossentropy’), optimizer, and include the accuracy metric in the model.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add the input layer (input_shape should match the number of features)\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add two hidden layers with ReLU activation\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with a sigmoid activation for binary classification\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',  # You can choose other optimizers like 'sgd', 'rmsprop', etc.\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4913d17-0678-404a-b489-246becadd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q11. Compile the model with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add the input layer (input_shape should match the number of features)\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Add two hidden layers with ReLU activation\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with a sigmoid activation for binary classification\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy',  # Specify your loss function\n",
    "              optimizer='adam',  # Specify your optimizer (e.g., 'adam', 'sgd', etc.)\n",
    "              metrics=['accuracy'])  # Specify your evaluation metrics (e.g., 'accuracy', 'precision', etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc104f-bf8d-4d92-a52b-e2ecf1033ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q12. Fit the model to the training data using appropriate batch size and number of epochs.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming you have already created and compiled the model as shown in previous responses\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(\n",
    "    X_train_scaled,  # Training features\n",
    "    y_train,         # Training labels\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_valid_scaled, y_valid)  # Validation data for monitoring during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48da127-bde1-4c37-aa99-b551430ccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Q13. Obtain the model's parameters (weights and biases).\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming you have already created and compiled the model as shown in previous responses\n",
    "\n",
    "# Get the model's parameters\n",
    "model_parameters = []\n",
    "\n",
    "# Iterate through each layer in the model\n",
    "for layer in model.layers:\n",
    "    # Check if the layer has weights (e.g., Dense layers have weights)\n",
    "    if hasattr(layer, 'get_weights'):\n",
    "        # Get the weights and biases for the layer\n",
    "        layer_params = layer.get_weights()\n",
    "        model_parameters.append(layer_params)\n",
    "\n",
    "# Display the model's parameters\n",
    "for i, params in enumerate(model_parameters):\n",
    "    print(f\"Layer {i + 1} - {model.layers[i].name}:\")\n",
    "    for j, param in enumerate(params):\n",
    "        print(f\"Parameter {j + 1} - Shape: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bed72-8893-4c38-b68c-82bbaf7f1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q14. Store the model's training history as a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already created, compiled, and trained the model as shown in previous responses\n",
    "\n",
    "# Convert the model's training history to a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(history_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf68c83-6bcb-4956-a7bb-a0b5a711da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already created, compiled, and trained the model as shown in previous responses\n",
    "\n",
    "# Access the training history from the 'history' object\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1940272-87d8-470b-b948-6e0972bfbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q16. Evaluate the model's performance using the test dataset and report relevant metrics.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming you have already created, compiled, and trained the model as shown in previous responses\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Report relevant metrics\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
