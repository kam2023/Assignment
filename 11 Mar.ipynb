{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e1d7fb-a6a5-4b57-8fbb-5193bee9bf59",
   "metadata": {},
   "source": [
    "# Q1: What is the difference between a t-test and a z-test? Provide an example scenario where you would\n",
    "# use each type of test.\n",
    "\n",
    "+ Both t-tests and z-tests are statistical hypothesis tests that are used to determine whether there is a significant difference between two groups or population means. However, there are some key differences between these tests.\n",
    "\n",
    "+ A t-test is used when the sample size is small (less than 30) or when the population variance is unknown. It is also used when the data being analyzed is not normally distributed. In a t-test, the test statistic is calculated using the t-distribution, which is a probability distribution that takes into account the sample size and the sample standard deviation.\n",
    "\n",
    "+ On the other hand, a z-test is used when the sample size is large (greater than 30) or when the population variance is known. In a z-test, the test statistic is calculated using the standard normal distribution, which is a probability distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "+ Example scenario where you would use each type of test:\n",
    "\n",
    "+ Suppose you want to compare the average height of two groups of people: Group A and Group B. Group A consists of 25 randomly selected men, and Group B consists of 30 randomly selected women. You don't know the population variance of the height of either group.\n",
    "\n",
    "+ To determine if there is a significant difference in the average height between Group A and Group B, you could use a t-test because the sample size of each group is less than 30. You would calculate the t-statistic, which would give you the probability that any difference in height between the groups is due to chance.\n",
    "\n",
    "+ Now, imagine that you have a large sample size of heights of men from the entire country (such as the height of all men in the US). You also have the population variance of this group. You want to compare the average height of a random sample of 500 men from your large sample to the average height of a random sample of 500 women from the same large sample.\n",
    "\n",
    "+ Since the sample size is large (n = 500) and the population variance is known, you could use a z-test to determine if there is a significant difference in the average height between the two groups. The z-test would allow you to calculate the probability that any difference in height between the groups is due to chance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e8f38-2d65-45f9-889a-28b1e7432be0",
   "metadata": {},
   "source": [
    "# Q2: Differentiate between one-tailed and two-tailed tests.\n",
    "\n",
    "+ In statistical hypothesis testing, a hypothesis test can be either one-tailed or two-tailed. The difference between them lies in the directionality of the hypothesis being tested.\n",
    "\n",
    "+ A one-tailed test is a statistical test in which the hypothesis being tested is directional, meaning that the test is focused on one direction of an effect. This means that the hypothesis is either predicting an increase or a decrease in a particular variable, but not both. The one-tailed test is used when there is a clear directional hypothesis based on prior knowledge or research.\n",
    "\n",
    "+ For example, let's say a researcher is testing whether a new medication increases the average lifespan of patients. The one-tailed hypothesis would be that the medication increases the lifespan of patients. The one-tailed test would focus only on the direction of the effect, and the critical region would be on one side of the distribution.\n",
    "\n",
    "+ On the other hand, a two-tailed test is a statistical test in which the hypothesis being tested is non-directional. This means that the hypothesis is predicting a difference between two variables, but not the direction of that difference. The two-tailed test is used when there is no clear directional hypothesis.\n",
    "\n",
    "+ For example, let's say a researcher is testing whether there is a significant difference in the average weight of males and females. The two-tailed hypothesis would be that there is a difference in weight between males and females. The two-tailed test would focus on both sides of the distribution, and the critical region would be divided between both sides of the distribution.\n",
    "\n",
    "+ In summary, a one-tailed test is used when the hypothesis is directional, while a two-tailed test is used when the hypothesis is non-directional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a5b4f-56ca-4e58-a7ef-1876d3413197",
   "metadata": {},
   "source": [
    "# Q3: Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for\n",
    "# each type of error.\n",
    "\n",
    "+ In statistical hypothesis testing, there are two types of errors that can occur: Type I and Type II errors.\n",
    "\n",
    "+ Type I error occurs when a null hypothesis is rejected when it is actually true. In other words, it is a false positive. It happens when we conclude that there is a significant effect or difference between two groups when in fact, there is no such difference. The probability of making a Type I error is denoted by alpha (α) and is usually set at a significance level of 0.05 or 0.01.\n",
    "\n",
    "+ Example scenario: A drug company is testing a new drug that is supposed to reduce blood pressure. The null hypothesis is that the drug has no effect on blood pressure, and the alternative hypothesis is that the drug reduces blood pressure. If the drug company concludes that the drug reduces blood pressure when it actually doesn't, it would be a Type I error.\n",
    "\n",
    "+ Type II error occurs when a null hypothesis is not rejected when it is actually false. In other words, it is a false negative. It happens when we fail to detect a significant effect or difference between two groups when in fact, there is such a difference. The probability of making a Type II error is denoted by beta (β).\n",
    "\n",
    "+ Example scenario: A drug company is testing a new drug that is supposed to reduce blood pressure. The null hypothesis is that the drug has no effect on blood pressure, and the alternative hypothesis is that the drug reduces blood pressure. If the drug company concludes that the drug has no effect on blood pressure when it actually does, it would be a Type II error.\n",
    "\n",
    "+ In summary, Type I error occurs when we falsely reject a true null hypothesis, while Type II error occurs when we fail to reject a false null hypothesis. It is important to minimize both types of errors when conducting hypothesis testing, but the trade-off between them is that reducing one type of error can increase the other. The level of significance chosen for a hypothesis test can also affect the likelihood of Type I and Type II errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3bd58-a530-46a7-9426-3d1ff9bbe656",
   "metadata": {},
   "source": [
    "# Q4: Explain Bayes's theorem with an example.\n",
    "\n",
    "+ Bayes's theorem is a fundamental concept in probability theory that provides a way to update our belief about the probability of an event based on new evidence or information. It helps us calculate the probability of a hypothesis given the evidence, and it is expressed mathematically as:\n",
    "\n",
    "+ P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "+ where:\n",
    "\n",
    "* P(H|E) is the posterior probability of the hypothesis given the evidence\n",
    "* P(E|H) is the likelihood of the evidence given the hypothesis\n",
    "* P(H) is the prior probability of the hypothesis\n",
    "* P(E) is the prior probability of the evidence\n",
    "\n",
    "+ Here's an example scenario to illustrate Bayes's theorem:\n",
    "\n",
    "+ Suppose we have a box containing 5 red balls and 3 blue balls. We randomly select one ball from the box, but we don't know its color. Our hypothesis is that the ball is red, and the evidence is that the selected ball is warm to the touch. We know from experience that red balls are more likely to be warm than blue balls. We can use Bayes's theorem to update our belief about the probability of the ball being red given the warm temperature.\n",
    "\n",
    "+ First, we need to estimate the prior probability of the hypothesis, which is the probability of the ball being red before we have any evidence. Since there are 5 red balls and 3 blue balls, the prior probability of selecting a red ball is 5/8 or 0.625. This is the initial probability that we assign to the hypothesis.\n",
    "\n",
    "+ Next, we need to estimate the likelihood of the evidence given the hypothesis, which is the probability of the warm temperature given that the ball is red. Let's assume that red balls are warm 90% of the time and blue balls are warm only 10% of the time. Therefore, the likelihood of the evidence given the hypothesis is 0.9.\n",
    "\n",
    "+ Finally, we need to estimate the probability of the evidence, which is the probability of the ball being warm regardless of its color. Let's assume that this probability is 0.5, which means that there is a 50% chance that the ball will be warm regardless of its color.\n",
    "\n",
    "+ Using Bayes's theorem, we can calculate the posterior probability of the hypothesis given the evidence:\n",
    "\n",
    "* P(H|E) = P(E|H) * P(H) / P(E)\n",
    "* P(H|E) = 0.9 * 0.625 / 0.5\n",
    "* P(H|E) = 1.125\n",
    "\n",
    "+ The posterior probability of the hypothesis is greater than 1 because our hypothesis was more likely to be true given the evidence. Therefore, we update our belief and conclude that the selected ball is more likely to be red than blue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410851f7-fe05-41bd-b385-d24a03799ff4",
   "metadata": {},
   "source": [
    "# Q5: What is a confidence interval? How to calculate the confidence interval, explain with an example.\n",
    "\n",
    "+ A confidence interval is a range of values that is used to estimate an unknown population parameter with a certain level of confidence. It is a measure of the precision of an estimate, and it is commonly used in statistical inference to determine the range of values within which the true population parameter is likely to lie.\n",
    "\n",
    "+ To calculate a confidence interval, we need to specify the level of confidence (often denoted as 1-α) and use a formula to compute the interval. The most commonly used formula for calculating a confidence interval for a population mean is:\n",
    "\n",
    "+ CI = X̄ ± Z* (s / √n)\n",
    "\n",
    "+ where:\n",
    "\n",
    "* X̄ is the sample mean\n",
    "* Z* is the critical value of the standard normal distribution corresponding to the level of confidence\n",
    "* s is the sample standard deviation\n",
    "* n is the sample size\n",
    "\n",
    "+ For example, suppose we want to estimate the average height of all college students in a certain state with 95% confidence. We take a random sample of 50 students and measure their heights. We find that the sample mean height is 68 inches and the sample standard deviation is 3 inches.\n",
    "\n",
    "+ To calculate the confidence interval, we need to determine the critical value of the standard normal distribution corresponding to the level of confidence. Since we want 95% confidence, the level of significance (α) is 0.05, and the critical value is ±1.96 (from a standard normal distribution table).\n",
    "\n",
    "+ Plugging in the values, we get:\n",
    "\n",
    "* CI = 68 ± 1.96 * (3 / √50)\n",
    "* CI = 68 ± 0.84\n",
    "* CI = [67.16, 68.84]\n",
    "\n",
    "+ This means that we are 95% confident that the true population mean height of all college students in the state falls between 67.16 and 68.84 inches. Note that if we take many random samples and calculate the confidence intervals, we expect about 95% of them to contain the true population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26941b7a-2cd7-4450-bc4a-7085825e3dad",
   "metadata": {},
   "source": [
    "# Q6. Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the\n",
    "# event's probability and new evidence. Provide a sample problem and solution.\n",
    "\n",
    "##  Suppose that a certain rare disease affects 0.1% of the population. A medical test is developed to detect the disease, but it is not perfect. The test has a false-positive rate of 2% (meaning that 2% of healthy people will test positive) and a false-negative rate of 1% (meaning that 1% of people with the disease will test negative). If a person tests positive, what is the probability that they actually have the disease?\n",
    "\n",
    "+ Let's use Bayes' Theorem to solve this problem. We want to find the probability of having the disease given a positive test result, which can be written as:\n",
    "\n",
    "+ P(Disease | Positive Test) = P(Positive Test | Disease) * P(Disease) / P(Positive Test)\n",
    "\n",
    "+ where:\n",
    "\n",
    "+ P(Disease | Positive Test) is the probability of having the disease given a positive test result (the posterior probability)\n",
    "+ P(Positive Test | Disease) is the probability of testing positive given that the person has the disease (the sensitivity of the test)\n",
    "+ P(Disease) is the prior probability of having the disease (0.1%)\n",
    "+ P(Positive Test) is the probability of testing positive (the denominator)\n",
    "+ To calculate the denominator, we can use the law of total probability:\n",
    "+ P(Positive Test) = P(Positive Test | Disease) * P(Disease) + P(Positive Test | No Disease) * P(No Disease)\n",
    "\n",
    "+ where:\n",
    "\n",
    "+ P(Positive Test | No Disease) is the probability of testing positive given that the person does not have the disease (the specificity of the test)\n",
    "+ P(No Disease) is the complement of the prior probability of having the disease (99.9%)\n",
    "+ Plugging in the values, we get:\n",
    "\n",
    "+ P(Positive Test) = 0.99 * 0.001 + 0.02 * 0.999\n",
    "+ P(Positive Test) = 0.02097\n",
    "\n",
    "+ Now we can calculate the posterior probability using Bayes' Theorem:\n",
    "\n",
    "+ P(Disease | Positive Test) = 0.99 * 0.001 / 0.02097\n",
    "+ P(Disease | Positive Test) = 0.047\n",
    "\n",
    "+ This means that if a person tests positive for the disease, the probability of actually having the disease is only about 4.7%. Even though the test is quite accurate, the low prevalence of the disease means that the false positives outnumber the true positives. Therefore, additional testing or confirmation may be necessary to confirm the diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0caa6cb-7375-4fdd-ad9a-dcdf7e469dd9",
   "metadata": {},
   "source": [
    "# Q7. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation\n",
    "# of 5. Interpret the results.\n",
    "\n",
    "+ To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we can use the formula:\n",
    "\n",
    "+ CI = X̄ ± Z* (s / √n)\n",
    "\n",
    "+ where:\n",
    "\n",
    "+ X̄ is the sample mean (50 in this case)\n",
    "+ Z* is the critical value of the standard normal distribution corresponding to the level of confidence (1.96 for 95% confidence)\n",
    "+ s is the sample standard deviation (5 in this case)\n",
    "+ n is the sample size (unknown in this case)\n",
    "+ Since the sample size (n) is unknown, we cannot calculate the exact confidence interval. However, we can provide a range of possible values for the sample size that would result in a 95% confidence interval with a mean of 50 and a standard deviation of 5.\n",
    "\n",
    "+ Using the formula, we can write:\n",
    "\n",
    "+ CI = 50 ± 1.96 * (5 / √n)\n",
    "\n",
    "+ Solving for n, we get:\n",
    "\n",
    "+ n = (1.96 * 5 / CI)^2\n",
    "\n",
    "+ Substituting the value for the confidence interval (CI) as 10 (twice the margin of error), we get:\n",
    "\n",
    "+ n = (1.96 * 5 / 10)^2\n",
    "+ n = 9.6\n",
    "\n",
    "+ This means that a sample size of 10 would result in a 95% confidence interval with a mean of 50 and a standard deviation of 5, with a margin of error of 5 (since the confidence interval is 50 ± 5). However, larger sample sizes would also result in a 95% confidence interval with the same mean and standard deviation, but with a smaller margin of error.\n",
    "\n",
    "+ Interpreting the results, we can say that we are 95% confident that the true population mean falls within the range of 45 to 55, based on the given sample. However, this statement assumes that the sample is representative of the population and that the underlying assumptions of the statistical test are valid. Additionally, since the sample size is not known, the exact confidence interval cannot be calculated, which may affect the precision of the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527b073-ab57-44c0-9c01-f17cb7326ccf",
   "metadata": {},
   "source": [
    "# Q8. What is the margin of error in a confidence interval? How does sample size affect the margin of error?\n",
    "# Provide an example of a scenario where a larger sample size would result in a smaller margin of error.\n",
    "\n",
    "+ The margin of error is a measure of the precision of a confidence interval, representing the range of values above and below the estimated population parameter within which the true population parameter is likely to fall. It is calculated by taking half the width of the confidence interval, and is expressed as a percentage or a unit of measurement, depending on the context.\n",
    "\n",
    "+ The margin of error is affected by several factors, including the level of confidence, the sample size, and the population variability. In general, a higher level of confidence requires a wider interval and thus a larger margin of error, while a larger sample size results in a narrower interval and thus a smaller margin of error. This is because larger sample sizes provide more information and reduce the effect of random variation, allowing for a more precise estimate of the population parameter.\n",
    "\n",
    "+ For example, suppose we want to estimate the proportion of voters in a city who support a particular candidate, using a 95% confidence interval with a margin of error of 3%. If we take a random sample of 500 voters and find that 60% of them support the candidate, we can calculate the confidence interval as:\n",
    "\n",
    "+ p̂ ± Z*√(p̂(1-p̂)/n)\n",
    "\n",
    "+ where p̂ is the sample proportion, n is the sample size, and Z* is the critical value of the standard normal distribution corresponding to the level of confidence (1.96 for 95% confidence).\n",
    "\n",
    "+ Substituting the values, we get:\n",
    "\n",
    "+ 0.60 ± 1.96√((0.60)(1-0.60)/500)\n",
    "+ 0.60 ± 0.046\n",
    "+ (0.554, 0.646)\n",
    "\n",
    "+ This means we are 95% confident that the true proportion of voters who support the candidate is between 55.4% and 64.6%, based on the given sample.\n",
    "\n",
    "+ Now suppose we increase the sample size to 1000. We can calculate the new margin of error as:\n",
    "\n",
    "+ 1.96√((0.60)(1-0.60)/1000)\n",
    "+ 0.031\n",
    "\n",
    "+ This means the new confidence interval would have a margin of error of 3.1%, which is smaller than the original margin of error of 4.6%. This indicates that a larger sample size provides a more precise estimate of the population parameter, resulting in a narrower confidence interval with a smaller margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff369d-d32e-4a91-9896-ebc1e58f952e",
   "metadata": {},
   "source": [
    "# Q9. Calculate the z-score for a data point with a value of 75, a population mean of 70, and a population\n",
    "# standard deviation of 5. Interpret the results.\n",
    "\n",
    "+ The z-score measures how many standard deviations a data point is from the mean of its population. It is calculated as:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "+ where x is the data point, μ is the population mean, and σ is the population standard deviation.\n",
    "\n",
    "+ Substituting the given values, we get:\n",
    "\n",
    "z = (75 - 70) / 5\n",
    "\n",
    "z = 1\n",
    "\n",
    "+ This means that the data point of 75 is 1 standard deviation above the population mean of 70. In other words, it is above the average value by a moderate amount. The positive sign of the z-score indicates that the data point is above the mean, while a negative z-score would indicate that the data point is below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b04e66-5bb7-4aed-b845-26efa7fcb6ee",
   "metadata": {},
   "source": [
    "# Q10. In a study of the effectiveness of a new weight loss drug, a sample of 50 participants lost an average\n",
    "# of 6 pounds with a standard deviation of 2.5 pounds. Conduct a hypothesis test to determine if the drug is\n",
    "# significantly effective at a 95% confidence level using a t-test.\n",
    "\n",
    "+ To conduct a hypothesis test for this scenario, we can follow the following steps:\n",
    "\n",
    "+ Step 1: State the null and alternative hypotheses.\n",
    "\n",
    "+ The null hypothesis (H0) is that the drug is not significantly effective, i.e., the population mean weight loss is not different from zero:\n",
    "\n",
    "H0: μ = 0\n",
    "\n",
    "+ The alternative hypothesis (Ha) is that the drug is significantly effective, i.e., the population mean weight loss is different from zero:\n",
    "\n",
    "Ha: μ ≠ 0\n",
    "\n",
    "+ Step 2: Determine the level of significance and select the appropriate test statistic.\n",
    "\n",
    "+ The level of significance (α) is 0.05, which corresponds to a 95% confidence level. Since the sample size is less than 30 and the population standard deviation is unknown, we can use a t-test with (n-1) degrees of freedom.\n",
    "\n",
    "+ Step 3: Calculate the test statistic and p-value.\n",
    "\n",
    "+ The t-test statistic can be calculated as:\n",
    "\n",
    "t = (x̄ - μ) / (s / √n)\n",
    "\n",
    "+ where x̄ is the sample mean, μ is the hypothesized population mean under the null hypothesis, s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "+ Substituting the given values, we get:\n",
    "\n",
    "t = (6 - 0) / (2.5 / √50)\n",
    "\n",
    "t = 13.42\n",
    "\n",
    "+ Using a t-distribution table with 49 degrees of freedom (df = n-1), we can find the p-value associated with this test statistic. The p-value is the probability of observing a test statistic as extreme or more extreme than the one calculated, assuming the null hypothesis is true.\n",
    "\n",
    "+ Based on the table, the p-value for a two-tailed test at a significance level of 0.05 with 49 degrees of freedom is less than 0.0001.\n",
    "\n",
    "+ Step 4: Make a decision and interpret the results.\n",
    "\n",
    "+ Since the p-value (less than 0.0001) is less than the significance level (0.05), we reject the null hypothesis and conclude that there is sufficient evidence to support the alternative hypothesis. This means that the weight loss drug is significantly effective at a 95% confidence level.\n",
    "\n",
    "+ In other words, we can be 95% confident that the true population mean weight loss is different from zero, based on the given sample. The effect size can be measured using Cohen's d, which is a standardized difference between the means. It can be calculated as:\n",
    "\n",
    "d = (x̄ - μ) / s\n",
    "\n",
    "+ where s is the pooled standard deviation, calculated as:\n",
    "\n",
    "+ s = √[(n1-1)s1^2 + (n2-1)s2^2] / (n1 + n2 - 2)\n",
    "\n",
    "+ Assuming a hypothetical control group with a mean weight loss of zero, we can calculate the effect size as:\n",
    "\n",
    "d = (6 - 0) / √[(49)(2.5^2) / 50]\n",
    "\n",
    "d = 4.27\n",
    "\n",
    "+ This indicates a large effect size, meaning that the weight loss drug has a significant impact on the average weight loss of the participants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0393be-037a-49a2-96ec-1f97c54fc51a",
   "metadata": {},
   "source": [
    "# Q11. In a survey of 500 people, 65% reported being satisfied with their current job. Calculate the 95%\n",
    "# confidence interval for the true proportion of people who are satisfied with their job.\n",
    "\n",
    "+ To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\n",
    "\n",
    "+ CI = p ± z* (sqrt(p*(1-p)/n))\n",
    "\n",
    "where:\n",
    "\n",
    "+ CI is the confidence interval\n",
    "+ p is the sample proportion\n",
    "+ z* is the critical value from the standard normal distribution for the desired confidence level (1.96 for a 95% confidence level)\n",
    "+ n is the sample size\n",
    "+ Substituting the given values, we get:\n",
    "\n",
    "CI = 0.65 ± 1.96 * (sqrt(0.65*(1-0.65)/500))\n",
    "\n",
    "\n",
    "CI = 0.65 ± 0.045\n",
    "\n",
    "\n",
    "CI = (0.605, 0.695)\n",
    "\n",
    "+ Interpretation: We can be 95% confident that the true proportion of people who are satisfied with their job is between 0.605 and 0.695 based on the given sample. This means that if we were to repeat the survey multiple times and calculate the confidence intervals, 95% of the intervals would contain the true population proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f7358-fd08-4fc9-bc0f-5b9609f9381b",
   "metadata": {},
   "source": [
    "# Q12. A researcher is testing the effectiveness of two different teaching methods on student performance.\n",
    "# Sample A has a mean score of 85 with a standard deviation of 6, while sample B has a mean score of 82\n",
    "# with a standard deviation of 5. Conduct a hypothesis test to determine if the two teaching methods have a\n",
    "# significant difference in student performance using a t-test with a significance level of 0.01.\n",
    "\n",
    "+ To conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance using a t-test, we can follow these steps:\n",
    "\n",
    "+ Step 1: State the null and alternative hypotheses\n",
    "\n",
    "+ Null hypothesis: There is no significant difference in student performance between the two teaching methods.\n",
    "+ Alternative hypothesis: There is a significant difference in student performance between the two teaching methods.\n",
    "+ Step 2: Set the significance level\n",
    "+ We are given a significance level of 0.01.\n",
    "\n",
    "+ Step 3: Determine the test statistic\n",
    "+ We can use the formula for a two-sample t-test to calculate the test statistic:\n",
    "\n",
    "t = (x̄1 - x̄2) / (s1^2/n1 + s2^2/n2)^0.5\n",
    "\n",
    "+ where:\n",
    "\n",
    "x̄1 and x̄2 are the sample means\n",
    "\n",
    "s1 and s2 are the sample standard deviations\n",
    "\n",
    "n1 and n2 are the sample sizes\n",
    "\n",
    "+ Substituting the given values, we get:\n",
    "\n",
    "\n",
    "t = (85 - 82) / ((6^2/ n1) + (5^2/n2))^0.5\n",
    "\n",
    "\n",
    "+ We don't have the sample sizes, so we assume they are equal and denote them as n. Then:\n",
    "\n",
    "\n",
    "t = (85 - 82) / ( ((6^2)+(5^2)) / n * 2 )^0.5\n",
    "\n",
    "\n",
    "t = 5.73 / 2.77 * (1/n)^0.5\n",
    "\n",
    "\n",
    "+ Step 4: Determine the critical value\n",
    "+ We need to determine the critical value for a t-distribution with (n1 + n2 - 2) degrees of freedom and a significance level of 0.01. Using a t-table or a calculator, we find the critical value to be ±2.602.\n",
    "\n",
    "+ Step 5: Make a decision and interpret the results\n",
    "\n",
    "+ If the calculated t-value falls within the critical region (i.e., outside the range of -2.602 to 2.602), we reject the null hypothesis and conclude that there is a significant difference in student performance between the two teaching methods. Otherwise, we fail to reject the null hypothesis and conclude that there is no significant difference.\n",
    "\n",
    "+ Since we are using a two-tailed test, we need to check if the calculated t-value falls outside the range of -2.602 to 2.602 in either direction.\n",
    "\n",
    "+ Let's assume a sample size of n = 30. Then:\n",
    "\n",
    "\n",
    "t = 5.73 / 2.77 * (1/30)^0.5\n",
    "\n",
    "\n",
    "t = 4.16\n",
    "\n",
    "+ Since the calculated t-value (4.16) falls outside the critical region, we reject the null hypothesis and conclude that there is a significant difference in student performance between the two teaching methods at a significance level of 0.01.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd578d-d4dd-48ab-ba16-e8e1c1957361",
   "metadata": {},
   "source": [
    "# Q13. A population has a mean of 60 and a standard deviation of 8. A sample of 50 observations has a mean\n",
    "# of 65. Calculate the 90% confidence interval for the true population mean.\n",
    "\n",
    "+ To calculate the 90% confidence interval for the true population mean, we can use the following formula:\n",
    "\n",
    "+ Confidence interval = sample mean ± (z-score * standard error)\n",
    "\n",
    "+ where:\n",
    "\n",
    "+ sample mean is the mean of the sample\n",
    "+ z-score is the critical value for the desired level of confidence (in this case, 90%)\n",
    "+ standard error is the standard deviation of the sample mean, which is calculated as the population standard deviation divided by the square root of the sample size.\n",
    "+ First, we calculate the standard error:\n",
    "\n",
    "+ standard error = population standard deviation / (sample size)^0.5\n",
    "\n",
    "+ standard error = 8 / (50)^0.5\n",
    "\n",
    "+ standard error = 1.13\n",
    "\n",
    "+ Next, we find the z-score for a 90% confidence level. Using a z-table or a calculator, we find the z-score to be 1.645.\n",
    "\n",
    "+ Finally, we plug in the values:\n",
    "\n",
    "+ Confidence interval = 65 ± (1.645 * 1.13)\n",
    "\n",
    "+ Confidence interval = [63.38, 66.62]\n",
    "\n",
    "+ Therefore, we can say with 90% confidence that the true population mean falls within the range of 63.38 to 66.62."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1c36a-b17e-442a-903a-9876420eab28",
   "metadata": {},
   "source": [
    "# Q14. In a study of the effects of caffeine on reaction time, a sample of 30 participants had an average\n",
    "# reaction time of 0.25 seconds with a standard deviation of 0.05 seconds. Conduct a hypothesis test to\n",
    "# determine if the caffeine has a significant effect on reaction time at a 90% confidence level using a t-test.\n",
    "\n",
    "+ To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we can use a t-test with the following null and alternative hypotheses:\n",
    "\n",
    "+ Null hypothesis (H0): The mean reaction time is not significantly different between the caffeine and control groups.\n",
    "\n",
    "+ Alternative hypothesis (Ha): The mean reaction time is significantly different between the caffeine and control groups.\n",
    "\n",
    "+ We can use a two-tailed t-test because the alternative hypothesis does not specify a direction of difference.\n",
    "\n",
    "+ The significance level is 1 - 0.9 = 0.1, which is split between the two tails of the distribution at 0.05 for each tail.\n",
    "\n",
    "+ We can calculate the t-value using the following formula:\n",
    "\n",
    "+ t = (sample mean - population mean) / (sample standard deviation / sqrt(sample size))\n",
    "\n",
    "+ where:\n",
    "\n",
    "+ sample mean is the mean of the sample\n",
    "+ population mean is the hypothetical mean of the null hypothesis (in this case, 0.25 seconds)\n",
    "+ sample standard deviation is the standard deviation of the sample\n",
    "+ sample size is the size of the sample.\n",
    "+ Plugging in the values, we get:\n",
    "\n",
    "t = (0.25 - 0) / (0.05 / sqrt(30))\n",
    "\n",
    "\n",
    "t = 5.48\n",
    "\n",
    "\n",
    "+ The degrees of freedom for the t-test are (sample size - 1) = 29. Using a t-table or a calculator, we find the critical t-value at a 0.05 significance level with 29 degrees of freedom to be ± 1.699.\n",
    "\n",
    "+ Since our calculated t-value (5.48) is greater than the critical t-value (1.699), we can reject the null hypothesis and conclude that there is a significant difference between the mean reaction time of the caffeine group and the control group at a 90% confidence level.\n",
    "\n",
    "+ Therefore, we can say with 90% confidence that caffeine has a significant effect on reaction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39ca69-c163-4d22-af03-4e4c9d12719b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
