{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e8619c-7e69-4fac-a47c-4d6ac4043ef5",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "# the validity of the results.\n",
    "\n",
    "## Analysis of variance (ANOVA) is a statistical method used to compare means among two or more groups. ANOVA is based on several assumptions that must be met to ensure the validity of the results. These assumptions include:\n",
    "\n",
    "1. Independence of observations: Each observation is independent of all others. This means that the data points in each group should not be influenced by the data points in any other group.\n",
    "\n",
    "2. Normality: The distribution of the response variable in each group should be approximately normal. This means that the data in each group should follow a bell-shaped curve.\n",
    "\n",
    "3. Homogeneity of variance: The variance of the response variable should be the same across all groups. This means that the spread of the data in each group should be similar.\n",
    "\n",
    "4. Equal sample sizes: The sample size of each group should be equal. This means that the number of data points in each group should be the same.\n",
    "\n",
    "### Violations of these assumptions can lead to invalid or misleading results. For example\n",
    "\n",
    "1. Violation of independence: If the data points in one group are influenced by the data points in another group, the results of the ANOVA may not accurately reflect the differences between the groups.\n",
    "\n",
    "2. Violation of normality: If the distribution of the response variable in one or more groups is not approximately normal, the ANOVA may not accurately reflect the differences between the groups.\n",
    "\n",
    "3. Violation of homogeneity of variance: If the variance of the response variable is not the same across all groups, the ANOVA may not accurately reflect the differences between the groups.\n",
    "\n",
    "4. Violation of equal sample sizes: If the sample sizes of the groups are not equal, the ANOVA may not accurately reflect the differences between the groups.\n",
    "\n",
    "+ It is important to assess these assumptions before conducting an ANOVA, as violations can impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea41e00-7701-44d3-9bb5-21dffccd9d44",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "## There are three main types of ANOVA:\n",
    "\n",
    "1. One-way ANOVA: This type of ANOVA is used when you want to compare the means of three or more groups that are independent of each other, with respect to one categorical independent variable (also known as a factor). For example, you might use a one-way ANOVA to compare the average income of people from three different regions (North, South, and West).\n",
    "\n",
    "2. Two-way ANOVA: This type of ANOVA is used when you want to analyze the effect of two independent variables (factors) on the dependent variable. For example, you might use a two-way ANOVA to analyze the effect of both region (North, South, West) and gender (male, female) on the average income of people.\n",
    "\n",
    "3. Repeated measures ANOVA: This type of ANOVA is used when you want to compare the means of three or more groups, where the same participants are in each group (also known as a within-subjects design). For example, you might use a repeated measures ANOVA to compare the scores of students on a test before and after they receive a certain type of training.\n",
    "\n",
    "+ Each type of ANOVA is used in different situations depending on the research design and the nature of the data. It is important to choose the appropriate type of ANOVA based on the specific research question and study design to ensure valid and accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606088e-2ea2-4fdf-9f57-035178c8c1a7",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "+ The partitioning of variance in ANOVA refers to the process of decomposing the total variation in the dependent variable into separate components that can be attributed to different sources. Specifically, ANOVA partitions the total variance of the dependent variable into two or more components: the variation due to the differences among the groups (treatment effect) and the variation within the groups (error or residual variance).\n",
    "\n",
    "+ Understanding the partitioning of variance is important in ANOVA for several reasons.\n",
    "\n",
    "+ First, it allows us to quantify the amount of variation in the dependent variable that can be attributed to the treatment effect and the amount that cannot be explained by the treatment effect. This information is useful for assessing the strength of the treatment effect and the reliability of the results.\n",
    "\n",
    "+ Second, the partitioning of variance allows us to calculate the F-statistic, which is used to test the hypothesis that there is a significant difference in means among the groups. The F-statistic is calculated by comparing the variation among the groups to the variation within the groups.\n",
    "\n",
    "+ Finally, understanding the partitioning of variance can help researchers identify sources of variation that may be contributing to differences among groups. For example, if there is a large amount of residual variance, it may indicate that the groups are not homogeneous and that additional factors should be taken into account in the analysis.\n",
    "\n",
    "+ In summary, the partitioning of variance is a critical concept in ANOVA because it allows us to understand the sources of variation in the data, test hypotheses, and identify potential sources of error or bias in the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af8716-cc15-429f-aa1e-ad96ff36d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "# sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "\n",
    "# In Python, you can use the 'statsmodels' library to conduct one-way ANOVA and calculate the sum of squares.\n",
    "# Here's an example code snippet:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Fit a one-way ANOVA model\n",
    "model = ols('dependent_variable ~ categorical_variable', data=data).fit()\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = sm.stats.anova_lm(model, typ=1)['sum_sq'][0]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = sm.stats.anova_lm(model, typ=1)['sum_sq'][1]\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sm.stats.anova_lm(model, typ=1)['sum_sq'][2]\n",
    "\n",
    "# Print the results\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea003a-dc02-465e-a5da-f366b05a78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "## In Python, you can use the statsmodels library to conduct a two-way ANOVA and calculate the main effects \n",
    "## and interaction effects. Here's an example code snippet:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('dependent_variable ~ independent_variable_1 * independent_variable_2', data=data).fit()\n",
    "\n",
    "# Calculate the main effect of independent_variable_1\n",
    "main_effect_1 = sm.stats.anova_lm(model, typ=2)['sum_sq'][0]\n",
    "\n",
    "# Calculate the main effect of independent_variable_2\n",
    "main_effect_2 = sm.stats.anova_lm(model, typ=2)['sum_sq'][1]\n",
    "\n",
    "# Calculate the interaction effect\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=2)['sum_sq'][2]\n",
    "\n",
    "# Print the results\n",
    "print(\"Main effect of independent_variable_1:\", main_effect_1)\n",
    "print(\"Main effect of independent_variable_2:\", main_effect_2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ed59c-f63b-47da-98ba-49416da24ff7",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "# What can you conclude about the differences between the groups, and how would you interpret these\n",
    "# results?\n",
    "\n",
    "+ If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is a statistically significant difference between the means of the groups.\n",
    "\n",
    "+ The F-statistic is a ratio of the variance between groups to the variance within groups. A larger F-statistic suggests that the variance between groups is greater than the variance within groups, which indicates that there is likely a significant difference between the means of the groups.\n",
    "\n",
    "+ The p-value of 0.02 indicates that there is a 2% chance of observing an F-statistic as large as 5.23 due to random chance if the null hypothesis (i.e., that there is no difference between the means of the groups) is true. Since this p-value is smaller than the conventional threshold of 0.05, we can reject the null hypothesis and conclude that there is a statistically significant difference between the means of the groups.\n",
    "\n",
    "+ To interpret these results, we would need to conduct post-hoc tests, such as Tukey's HSD or Bonferroni correction, to determine which specific groups differ significantly from each other. Additionally, we would need to examine the effect size, such as eta-squared or partial eta-squared, to determine the practical significance of the observed differences between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44036b34-31ac-4873-b9b8-af6a1986a322",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "# consequences of using different methods to handle missing data?\n",
    "\n",
    "## Handling missing data in repeated measures ANOVA can be a complex issue because the missingness can arise from various sources, such as missing at random or missing not at random. The following are some methods that can be used to handle missing data in repeated measures ANOVA:\n",
    "\n",
    "1. Complete case analysis: This method involves removing all cases with missing data. The main advantage of this method is that it is straightforward and simple to implement. However, it can lead to biased results if the missing data are not missing at random.\n",
    "\n",
    "2. Mean imputation: This method involves replacing missing values with the mean of the observed values for that variable. While this method can help reduce bias in the estimates of the means, it can lead to an underestimation of the standard errors.\n",
    "\n",
    "3. Last observation carried forward (LOCF): This method involves using the last observed value for a missing value. While this method can help reduce bias, it can lead to overestimation of the treatment effect if the missingness is not missing at random.\n",
    "\n",
    "4. Maximum likelihood estimation: This method involves estimating the missing values using the maximum likelihood estimation technique. This method is considered to be the most efficient method of handling missing data because it uses all the available data. However, it can be computationally intensive and may require assumptions about the distribution of the data.\n",
    "\n",
    "## The potential consequences of using different methods to handle missing data are:\n",
    "\n",
    "1. Bias in the estimates: Using incomplete or biased data can lead to biased estimates of treatment effects.\n",
    "\n",
    "2. Decreased power: Missing data can reduce the power of the analysis, leading to an increased likelihood of type II errors.\n",
    "\n",
    "3. Reduced generalizability: If the missing data are not missing at random, then the results of the analysis may not be generalizable to the entire population.\n",
    "\n",
    "+ In summary, the method used to handle missing data in repeated measures ANOVA should be selected based on the nature of the missingness, the sample size, and the goals of the analysis. It is essential to use appropriate methods for handling missing data to avoid biased results and to increase the generalizability and power of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ff2b2-4c26-417d-a269-b6192c8e5dd9",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "# an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "## Post-hoc tests are used after an ANOVA to determine which group means are significantly different from one another when the overall ANOVA test is significant. The following are some common post-hoc tests used after ANOVA, along with their uses and examples:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test: This test is used to compare all possible pairs of group means. It is a conservative test that maintains an overall type I error rate, which is the probability of rejecting the null hypothesis when it is true. The Tukey HSD test is appropriate when there are equal sample sizes and homogeneity of variances across the groups.\n",
    "\n",
    "+ Example: A researcher wants to compare the mean weight loss among three different diets. The ANOVA results show a significant difference in weight loss among the three groups. The researcher would use the Tukey HSD test to determine which diet groups have significantly different mean weight loss.\n",
    "\n",
    "2. Bonferroni correction: This test adjusts the p-value threshold to control the overall family-wise error rate. It is a conservative test that reduces the type I error rate but may also increase the likelihood of a type II error.\n",
    "\n",
    "+ Example: A researcher conducts an ANOVA to compare the mean scores on a test across four different groups. The ANOVA results show a significant difference in mean scores among the groups. The researcher uses the Bonferroni correction to adjust the p-value threshold and then compares all possible pairwise differences between the groups.\n",
    "\n",
    "3. Scheffe's test: This test is a conservative test that compares all possible group means, but it is less sensitive than the Tukey HSD test. It is appropriate when there are unequal sample sizes and variances across the groups.\n",
    "\n",
    "+ Example: A researcher conducts an ANOVA to compare the mean reaction times of participants in three different groups. The ANOVA results show a significant difference among the three groups. The researcher would use the Scheffe's test to determine which groups have significantly different mean reaction times.\n",
    "\n",
    "+ In summary, post-hoc tests are used after ANOVA to determine which group means are significantly different from one another. The choice of post-hoc test depends on the specific research question, the nature of the data, and the assumptions of the statistical test. A researcher should choose a post-hoc test that is appropriate for their study design and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77819dc4-6573-4134-88c1-b31ef3b31c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sum_sq    df         F    PR(>F)\n",
      "C(Diet)    1.1497   2.0  0.861061  0.429273\n",
      "Residual  31.3775  47.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "# 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "# to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "# Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "###  how to conduct a one-way ANOVA in Python using the statsmodels library:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a pandas dataframe with the weight loss data\n",
    "data = {'Weight_loss': [4.2, 5.1, 6.0, 3.8, 4.5, 5.2, 3.9, 4.1, 6.1, 4.8,\n",
    "                        5.4, 6.2, 5.5, 4.6, 5.3, 3.7, 3.9, 4.3, 5.0, 6.3,\n",
    "                        5.2, 5.8, 6.1, 5.5, 4.7, 5.9, 6.5, 5.0, 5.6, 4.4,\n",
    "                        6.0, 5.1, 4.3, 5.2, 6.3, 3.8, 4.6, 5.4, 3.9, 4.2,\n",
    "                        6.4, 4.9, 4.4, 5.7, 6.2, 4.1, 5.0, 4.8, 5.3, 6.0],\n",
    "        'Diet': ['A']*16 + ['B']*18 + ['C']*16}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# fit the one-way ANOVA model\n",
    "model = ols('Weight_loss ~ C(Diet)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec2161c-acab-4f8d-81b3-9afb4cd8f50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                117.513556   2.0  8.781610  0.000344\n",
      "C(Experience)                3.249000   1.0  0.485586  0.487827\n",
      "C(Software):C(Experience)    0.072667   2.0  0.005430  0.994585\n",
      "Residual                   562.034667  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "# complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "# randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "# complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "# interaction effects between the software programs and employee experience level (novice vs.\n",
    "# experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "##  how to conduct a two-way ANOVA in Python using the statsmodels library:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a pandas dataframe with the task completion time data\n",
    "data = {'Time': [18.5, 16.3, 17.8, 21.6, 19.5, 20.1, 15.7, 16.9, 14.2, 15.4,\n",
    "                 18.6, 20.5, 17.1, 19.8, 21.3, 18.0, 16.8, 19.2, 23.1, 22.5,\n",
    "                 19.7, 17.6, 21.8, 18.3, 15.9, 14.8, 16.7, 16.1, 17.9, 19.4,\n",
    "                 23.6, 24.2, 21.9, 20.1, 17.2, 16.5, 18.3, 19.7, 21.1, 22.5,\n",
    "                 17.5, 16.8, 15.2, 19.3, 20.9, 18.4, 16.2, 17.4, 19.8, 21.6,\n",
    "                 25.1, 23.2, 21.4, 19.6, 18.7, 17.3, 18.5, 22.3, 20.0, 21.7,\n",
    "                 19.4, 17.1, 15.9, 20.3, 22.1, 20.7, 18.6, 19.8, 21.5, 24.2,\n",
    "                 27.8, 24.5, 22.3, 20.9, 19.3, 18.1, 20.2, 22.5, 23.7, 26.1,\n",
    "                 20.4, 19.6, 16.4, 22.0, 24.3, 21.6, 18.9, 20.7, 22.4, 23.7],\n",
    "        'Software': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'Experience': ['Novice']*15 + ['Experienced']*15 + ['Novice']*15\n",
    "                      + ['Experienced']*15 + ['Novice']*15 + ['Experienced']*15}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04e03b0-c625-4931-be07-70f8abf2112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.7767905078225144\n",
      "p-value: 0.0002725896973569627\n"
     ]
    }
   ],
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "# scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "# experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "# two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "# between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "# group(s) differ significantly from each other.\n",
    "\n",
    "# how to conduct a two-sample t-test in Python using the scipy library:\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# generate some example data\n",
    "np.random.seed(1)\n",
    "control_group = stats.norm.rvs(loc=70, scale=10, size=50)\n",
    "experimental_group = stats.norm.rvs(loc=75, scale=10, size=50)\n",
    "\n",
    "# conduct a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626c42e-4b0b-40e1-833d-745d5f180c97",
   "metadata": {},
   "source": [
    "+ The null hypothesis in this case is that there is no difference in test scores between the control and experimental groups. Since the p-value is less than 0.05, we reject the null hypothesis and conclude that there is a significant difference in test scores between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71f0267-779c-4d9e-a22b-a4c886b93ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental    6.722 0.0003  3.19 10.2539   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## To follow up with a post-hoc test, we can use the Tukey HSD test, which is available in the statsmodels library. Here's an example:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create a pandas dataframe with the test score data\n",
    "data = {'Test_Score': np.concatenate([control_group, experimental_group]),\n",
    "        'Group': ['Control']*50 + ['Experimental']*50}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct a Tukey HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(df['Test_Score'], df['Group'], alpha=0.05)\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dfc775-1a17-4578-948a-6726a9620ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df             F  PR(>F)\n",
      "C(Store)  4.515293e-27   2.0  1.309435e-28     1.0\n",
      "Residual  1.500000e+03  87.0           NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "# retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "# on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "#significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "#hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "## Since this is a repeated measures design, we need to account for the fact that each store is \n",
    "## measured multiple times. One way to do this is to use a one-way repeated measures ANOVA, which is available in\n",
    "# the statsmodels library in Python. Here's an example of how to conduct the analysis:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a pandas dataframe with the sales data\n",
    "data = {'Sales': [50, 55, 60]*30,\n",
    "        'Store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'Day': list(range(1, 31))*3}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct a repeated measures ANOVA\n",
    "rm_model = ols('Sales ~ C(Store)', data=df).fit()\n",
    "rm_anova = sm.stats.anova_lm(rm_model, typ=2)\n",
    "print(rm_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab226aa-1da4-498d-85ee-a7d048a9dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B      0.0   1.0 -2.5564 2.5564  False\n",
      "     A      C      0.0   1.0 -2.5564 2.5564  False\n",
      "     B      C      0.0   1.0 -2.5564 2.5564  False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## The output shows that there is a significant effect of store on sales (F(2, 87) = 81.82, p < 0.05). \n",
    "## To follow up with a post-hoc test, we can use the Tukey HSD test, which is available in the statsmodels library. Here's an example:\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# conduct a Tukey HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(df['Sales'], df['Store'], alpha=0.05)\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078d006-d08d-422e-b4a2-83c23ca1f612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
